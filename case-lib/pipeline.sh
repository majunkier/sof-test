#!/bin/bash

# Parse and validate multiple topology files from colon/comma-separated input
# Args: $1: topology path(s) - can be single file or colon/comma-separated list
# Returns: Sets global TPLG_FILES (comma-separated) and TPLG_COUNT
# Example: func_tplg_parse_and_validate "$TPLG"
func_tplg_parse_and_validate()
{
    local tplg_input="$1"
    tplg_input="${tplg_input//,/:}"  # Normalize to colon separator
    IFS=':' read -ra tplg_array <<< "$tplg_input"

    # Validate and collect accessible topologies
    local -a valid_tplg_list=()
    for single_tplg in "${tplg_array[@]}"; do
        single_tplg="${single_tplg## }"; single_tplg="${single_tplg%% }"  # Trim whitespace
        [[ -z "$single_tplg" ]] && continue

        local tplg_path
        tplg_path=$(func_lib_get_tplg_path "$single_tplg") && \
            valid_tplg_list+=("$tplg_path") || \
            dlogw "Topology $single_tplg not found, skipping"
    done

    [ ${#valid_tplg_list[@]} -eq 0 ] && die "No topology found from: $tplg_input"

    # Export as global variables
    export TPLG_FILES=$(IFS=,; echo "${valid_tplg_list[*]}")
    export TPLG_COUNT=${#valid_tplg_list[@]}
}

# This function will evaluate pipeline parameter related shell code generated by
# - sof-tplgreader.py (for SOF, pipeline parameters dumped from topology)
# - sof-dump-status.py (for legacy HDA, pipeline paramters dumped from proc)
# Args: $1: SOF topology path
#       $2: Pipeline filter in string form
# Note: for legacy HDA, topology is not present, $1 will be empty.
func_pipeline_export()
{

    # function parameter check
    if [ $# -ne 2 ]; then
        die "Not enough parameters, expect two parameters: topology path and pipeline filter"
    fi

    # For legacy HDA platform, there is no topology, we have to export pipeline
    # parameters from proc file system.
    is_sof_used || {
        [ "$FALLBACK_TO_PROC" == "true" ] ||
            die "No SOF sound card found and fallback mode disabled, failing."

        filter_str="$2"
        dlogi "No SOF sound card found, exporting pipeline parameters from proc file system"
        tmp_pipeline_params=$(mktemp /tmp/pipeline-params.XXXXXXXX)
        sof-dump-status.py -e "$filter_str" > "$tmp_pipeline_params" ||
            die "Failed to export pipeline parameters from proc file system"
        # shellcheck disable=SC1090
        source "$tmp_pipeline_params" || return 1
        rm "$tmp_pipeline_params"
        [ "$PIPELINE_COUNT" -ne 0 ] || die "No pipeline found from proc file system"
        return 0
    }

    # Support multiple topologies separated by colon (:) or comma (,)
    # sof-tplgreader.py natively supports multiple files with comma separator
    func_tplg_parse_and_validate "$1"
    local tplg_files="$TPLG_FILES"

    dlogi "$SCRIPT_NAME will use $TPLG_COUNT topology file(s) to run the test case"

    # create block option string
    local ignore=""
    if [ ${#TPLG_IGNORE_LST[@]} -ne 0 ]; then
        for key in "${!TPLG_IGNORE_LST[@]}"
        do
            dlogi "Pipeline list to ignore is specified, will ignore '$key=${TPLG_IGNORE_LST[$key]}' in test case"
            ignore=$ignore" $key:${TPLG_IGNORE_LST[$key]}"
        done
    fi

    local opt="$2"
    # In no HDMI mode, exclude HDMI pipelines
    [ -z "$NO_HDMI_MODE" ] || opt="$opt & ~pcm:HDMI"
    # In no Bluetooth mode, exclude BT pipelines
    [ -z "$NO_BT_MODE" ] || opt="$opt & ~pcm:Bluetooth"
    # In no DMIC mode, exclude DMIC pipelines
    [ -z "$NO_DMIC_MODE" ] || opt="$opt & ~pcm:DMIC"
    opt="-f '${opt}'"

    [[ "$ignore" ]] && opt="$opt -b '$ignore'"
    [[ "$SOFCARD" ]] && opt="$opt -s $SOFCARD"

    # sof-tplgreader.py handles multiple files natively with comma separator
    local -a pipeline_lst=()
    local cmd="sof-tplgreader.py $tplg_files $opt -e" line=""
    dlogi "Run command to get pipeline parameters from all topologies"
    dlogc "$cmd"

    # Capture output and check for errors
    local output exit_code
    output=$(eval "$cmd" 2>&1)
    exit_code=$?

    if [ $exit_code -ne 0 ]; then
        dloge "sof-tplgreader.py failed with exit code $exit_code"
        dloge "Command: $cmd"
        dloge "Output: $output"
        echo "ERROR: sof-tplgreader.py failed (exit $exit_code)" >&2
        echo "Command: $cmd" >&2
        echo "Output: $output" >&2
        die "Failed to parse topologies"
    fi

    # Read output into array
    readarray -t pipeline_lst <<< "$output"

    # Check if we got any output
    if [ ${#pipeline_lst[@]} -eq 0 ] || [ -z "${pipeline_lst[0]}" ]; then
        dloge "sof-tplgreader.py returned no output"
        dloge "Topologies: ${valid_tplg_list[*]}"
        echo "ERROR: No output from sof-tplgreader.py" >&2
        echo "Command: $cmd" >&2
        die "No pipeline data from topologies"
    fi

    # Evaluate all collected pipeline parameters first
    for line in "${pipeline_lst[@]}"; do
        eval "$line"
    done

    # Deduplicate pipelines by 'dev' field (hw:X,Y)
    # Same PCM device can be defined in multiple topology files
    # Always deduplicate to ensure no duplicate testing (harmless with single topology)
    if [ "${PIPELINE_COUNT:-0}" -gt 0 ]; then
        local orig_count=$PIPELINE_COUNT
        local -A seen_devs=()
        local new_idx=0

        # Iterate through all pipelines and keep only first occurrence of each unique 'dev'
        for idx in $(seq 0 $((PIPELINE_COUNT - 1))); do
            local dev_val=$(func_pipeline_parse_value "$idx" "dev")

            # Skip if we've seen this dev before
            if [[ -n "${seen_devs[$dev_val]}" ]]; then
                continue
            fi
            seen_devs["$dev_val"]=1

            # If this is a new unique dev, copy pipeline to new index if needed
            if [ $new_idx -ne $idx ]; then
                # Copy all fields from old index to new index
                for key in pcm id dev type fmt fmts rate rates channel channels snd; do
                    local val=$(func_pipeline_parse_value "$idx" "$key")
                    if [[ -n "$val" ]]; then
                        eval "PIPELINE_${new_idx}[$key]=\"$val\""
                    fi
                done
            fi
            new_idx=$((new_idx + 1))
        done

        # Update pipeline count
        PIPELINE_COUNT=$new_idx
        dlogi "Deduplicated $orig_count pipelines to $PIPELINE_COUNT unique devices"
    fi

    [[ ! "$PIPELINE_COUNT" ]] && die "Failed to parse topologies, please check topology parsing command"
    [[ $PIPELINE_COUNT -eq 0 ]] && dlogw "No pipeline found with option: $opt, unable to run $SCRIPT_NAME" && exit 2
    return 0
}

func_pipeline_parse_value()
{
    local idx=$1
    local key=$2
    if [[ $idx -ge $PIPELINE_COUNT ]]; then
        echo ""
        return 0
    fi
    local array_key='PIPELINE_'"$idx"'['"$key"']'
    eval echo "\${$array_key}" # dynmaic echo the target value of the PIPELINE
}
